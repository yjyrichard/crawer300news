标题: 专访腾讯云副总裁答治茜：大模型时代下，知识库是企业的基础设施
分类: 科技
时间: 2025-10-27 22:17:06
来源: 网易新闻
链接: https://www.163.com/dy/article/KCTKRLNK0512B07B.html

==================================================
正文
==================================================

在实体经济和数字经济日益深度融合的大背景下，越来越多企业正积极拥抱大模型。不过，对于安全性、准确性要求极高的金融行业来说，通用大模型往往无法满足其需求。 “在实际落地过程中，‘大模型+企业知识库’成为AI落地的最佳路径。”近日，腾讯云副总裁答治茜在接受《每日经济新闻》（以下简称NBD）记者专访时坦言，金融机构普遍面临着知识孤岛化、非结构化数据海量、合规成本高企等知识管理的困境。 如何破解金融行业知识管理困境？金融行业对“大模型+知识库”的关注点呈现怎样的特点？如何看待大模型落地过程中出现的“杜撰”“错配”等现象？围绕这一系列话题，答治茜为记者进行了详细的解答。 大模型是“大脑”，知识库是“课本” 当前，大模型技术正惠及千行百业，金融行业也在探索符合金融规律的AI（人工智能）知识库建设路径。AI知识库作为连接数据、算法与场景的核心枢纽，是金融机构实现“从技术到价值”转化的关键抓手。 NBD：大模型时代，企业的“知识库”扮演了什么角色？金融领域专属模型和通用大模型有什么差别？ 答治茜 图片来源：受访者 答治茜：在大模型时代下，我们认为知识库是企业的一种基础设施。大模型是“大脑”，知识库是“课本”，大脑智力再高，如果没有学习过相关的知识，也无法很好地解决问题。 “通用大模型+专业领域知识库”的研发类似“大脑+课本”模式。首先，需要投入巨大资源训练一个“万事通”基座模型，或者直接采用市面上已有的效果最优的模型，使其具备强大的语言理解、逻辑推理和代码能力。然后，通过RAG（Retrieval-augmented Generation检索增强生成）技术，为这个“通才”配备一个庞大的、实时更新的金融知识库，如行业研报、公司公告、实时新闻、风控规则等。这种模式的优势是灵活性高、迭代快、成本相对可控。 而“金融领域专属模型”的研发类似“科班出身”模式，从模型训练的第一天起，就使用海量且高质量的金融领域私有数据进行从零开始的预训练，让模型从“基因”里就深刻理解金融术语、市场逻辑和专业范式。 允许员工个人创建知识库空间 对银行、证券、保险等企业的从业者而言，企业知识库早已不是简单的文档管理系统，而是承载着风险管控、合规审查、客户服务等核心职能的“智能大脑”。 NBD：金融行业对“大模型+知识库”的关注点呈现怎样的特点？ 答治茜：首先，金融行业对于知识库安全与合规的要求更高。 由于金融行业监管的特殊性，数据安全、监管要求、信创适配等成为数字化建设底线。所以，为了更好满足金融企业的需求，我们AI知识库建设需要有更专业化的能力，比如精细化的多级权限管理体系、防泄露的页面水印、严谨的审计能力和内容风控体系等。 其次，金融行业对知识问答准确性和严谨性的要求极高。 金融是非常严谨的行业，员工每天都在跟数字和知识打交道，所以知识内容非常丰富，也很复杂，而且大家对于知识库的期待很高，如希望多表格数据的计算、财报里多模态数据的解读、银行理财产品推荐等等，这对我们提出很大的挑战。为此，我们专门在AI出图、表格计算、知识溯源等方面下了很多功夫，并取得了阶段性突破。 再次，金融行业更关注员工个人知识的沉淀。在与银行、资管企业沟通过程中，我们发现很多金融企业非常希望员工个人的经验知识能沉淀下来，把个人经验变成企业知识。另外，我们发现很多金融企业员工日常需要的知识内容也是有差异的，所以“个人知识库”的概念今年被广泛关注，我们在知识库中设计了允许员工个人创建知识库空间的功能，同时打通微信、腾讯文档、企业微信等。 NBD：数据安全是企业发展过程中非常重要的环节，对于金融企业来说尤其如此，您如何看待数据安全问题？ 答治茜：金融行业对于监管、数据运营等有非常高的数据安全和隐私保护的要求。我们要从两个方面思考： 一是技术和产品层面，从应用到数据、算力等所有的基础设施，要实现私有化部署和全链路的安全。 另一个层面是运营层面，综合考虑管理和技术。比如说金融机构内部某团队有两三百人时，内部如何协同、如何按层级划分权限，哪些信息能让哪些人看到，这就是管理要求，要满足多级的授权管理。 如何避免幻觉：不乱说、能溯源、有效管理知识 在使用AI助手咨询某个问题时，经常得到错误的回复，这种现象在AI圈被称为“幻觉”，“幻觉”问题困扰着所有使用大语言模型的人。 NBD：个人使用大模型问答的时候会出现一些杜撰错误。如何看待大模型落地过程中出现的“杜撰”“错配”等问题？ 答治茜：ChatGPT出来后，我们就在思考大模型时代下行业会有什么样的变化。2024年开始，乐享就转型聚焦做AI知识库，目前在产品功能、问答准确性上应该是比较领先的。 当前大模型“杜撰”的情况还比较普遍，我认为破解的关键在于三方面：答案模糊的时候拒答不乱说、输出能有效溯源、企业内部知识实现有效治理（比如有效性和及时更新等）。考虑到乐享定位为企业级知识库，我们做了非常多的工作去提高准确性。主要是以下几方面： 第一，对文档、知识进行理解。我们自研OCR（Optical Character Recognition,光学字符识别）大模型，对复杂的图文混排文档解析准确率提升30%以上。 第二，理解后按照一定的规则对文档、知识进行切片存储。我们自研业界首个基于语义切分的模型，保障切分片段语义的完整性。 第三，当用户通过AI助手来问答时，我们会结合上下文对用户的问题进行理解后并改写，从而提升检索精度。 第四，基于改写后的用户问题，使用向量检索和关键词检索的混合检索模式，找到最相关的内容。 第五，上一步可能检索到大量内容，但并非所有内容都与问题紧密相关，因此需要对这些内容进行重新排序与过滤。 第六，基于重排后的内容调用大模型生成最终的答案。 经过以上程序，目前我们的准确率超过92%，我们会持续投入精力去提升准确率。